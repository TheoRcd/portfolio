<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Théo Richard – Product Designer</title>
    <meta name="description"
        content="I’m a Product Designer. I solve complex problems by organising information logically and making data-informed decisions to deliver simple solutions.">
    <meta name="robots" content="index, follow">
    <link rel="canonical" href="https://www.theorichard.com/">
    <link rel="icon" href="assets/favicons/favicon.svg" type="image/svg+xml">
    <link rel="icon" href="assets/favicons/favicon.ico" type="image/x-icon">
    <link rel="icon" href="assets/favicons/favicon-32x32.png" sizes="32x32">
    <link rel="stylesheet" href="css/main.css">
</head>

<body class="fade">
    <div class="custom-cursor"></div>
    <header>
        <div id="header-container">
            <a href="index.html" class="button-link button-back">
                <button class="button-secondary" tabindex="-1"><svg width="16" height="16" viewBox="0 0 16 16"
                        fill="currentColor" xmlns="http://www.w3.org/2000/svg">
                        <path fill-rule="evenodd" clip-rule="evenodd"
                            d="M4.41422 8.99999L7.70711 12.2929C8.09764 12.6834 8.09764 13.3166 7.70711 13.7071C7.31659 14.0976 6.68343 14.0976 6.2929 13.7071L1.2929 8.70711C0.902376 8.31658 0.902375 7.68342 1.2929 7.29289L6.2929 2.29289C6.68342 1.90237 7.31659 1.90237 7.70711 2.29289C8.09764 2.68342 8.09764 3.31658 7.70711 3.70711L4.41423 6.99999L14 7.00001C14.5523 7.00001 15 7.44773 15 8.00001C15 8.5523 14.5523 9.00001 14 9.00001L4.41422 8.99999Z"
                            fill="currentColor" />
                    </svg>Back</button>
            </a>
            <a href="index.html" class="button-link" id="logo">
                <img src="assets/icons/logo.png" alt="">
            </a>
            <a href="assets/resume/theo-richard-resume-2025.pdf" download="theo-richard-resume-2025.pdf" target="_blank"
                id="download-resume">
                <button class="button" tabindex="-1">Resume<img src="assets/icons/arrow-down-light.svg" alt=""></button>
            </a>
    </header>
    <main class="content article-container">
        <div class="article-header">
            <div class="article-cover">
                <h1>Motion</h1>
                <p>Sep 2022</p>
            </div>
            <div class="summary-container">
                <div class="summary-divider">
                    <div class="divider-block">
                        <h4>My role</h4>
                        <ul>
                            <li>Lead designer</li>
                        </ul>
                    </div>
                    <div class="divider-block">
                        <h4>Platforms</h4>
                        <ul>
                            <li>iOS, Android, Web</li>
                        </ul>
                    </div>
                    <div class="divider-block">
                        <h4>Year</h4>
                        <ul>
                            <li>2021 -> 2023</li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
        <div class="article-content">
            <div class="article-section">
                <h2>Overview</h2>
                <div class="section-content">
                    <div class="section-segment">
                        <h3>Context</h3>
                        <p>At Onfido, we help protect businesses against fraud by verifying their customers’ identities.
                            This process requires users to take a photo or a video of their identity documents and their
                            faces. In what follows, I relate the creation of the new Motion product and how we improved
                            the face-capture experience through user empathy, cross-functional collaboration, and an
                            iterative process.</p>
                    </div>
                    <div class="section-segment">
                        <h3>My team</h3>
                        <p>Initially, the team included a Product Designer (myself), a User Experience Researcher (Sofya
                            Bourne), and Applied Scientists. Our objective was to find opportunities to improve Onfido’s
                            facial verification solutions. Today, due to the value this project has generated, our team
                            is bigger. I am now working directly with a Product Manager, Engineering Leads, Front-End
                            engineers, a Test Engineer, and a Product Analyst.</p>
                        <p>My role was to design the best-in-class user experience for the new facial verification
                            product and to support my team in its implementation. I was involved in all stages of this
                            product’s creation: from ideation to the release.</p>
                    </div>
                    <div class="section-segment">
                        <h3>Context</h3>
                        <p>At Onfido, we help protect businesses against fraud by verifying their customers’ identities.
                            This process requires users to take a photo or a video of their identity documents and their
                            faces. In what follows, I relate the creation of the new Motion product and how we improved
                            the face-capture experience through user empathy, cross-functional collaboration, and an
                            iterative process.</p>
                        <div class="segment-divider">
                            <div class="divider-block">
                                <h4>1. User problem</h4>
                                <ul>
                                    <li>Our current Selfie Video product was designed to block more advanced fraud than
                                        our Selfie Photo product by adding movement and voice challenges. Specifically,
                                        it asked users to do a head-turn and to read out loud 3 random digits. These
                                        challenges lacked granular feedback and added complexity which could mean too
                                        much negative friction for genuine users, resulting in frustration, drop-off,
                                        and false rejections.</li>
                                </ul>
                            </div>
                            <div class="divider-block">
                                <h4>2. Business problem</h4>
                                <ul>
                                    <li>The Selfie Video product is good at catching more advanced fraud but was not
                                        designed for automation. Its manual reviews take longer processing time and have
                                        higher costs.</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                    <div class="section-segment">
                        <h3>Goals</h3>
                        <p>I was responsible for both setting user experience goals and ensuring we meet them. In
                            addition, I contributed to setting product performance goals.</p>
                        <p>On the whole, our objective was to create a simple, smooth, and pleasant user experience
                            which would be accessible and transparent. At the same time, we were to achieve full
                            automation, reduce processing time, reduce False Acceptance Rates and False Rejection Rates,
                            and achieve iBeta level 2 compliance (a fraud performance industry standard).</p>
                    </div>
                </div>
            </div>
            <div class="article-highlight">
                <p>
                    <span class="solid-text">How might we make our facial scan product</span>
                    <span class="gradient-text">easy to use, fraud-proof and automated?</span>
                </p>
            </div>
            <div class="article-section">
                <h2>Design process</h2>
                <div class="section-content">
                    <div class="section-segment">
                        <p>I worked closely with <a href="" target="_blank">Sofya Bourne</a>, who led the UX Research.
                            Together we planned the research, sampled the qualitative and quantitative data it had
                            produced, and translated it into insights to ensure we achieved our goals. Overall, this
                            project included 11 rounds of user research and design iterations. We created 30 design
                            prototypes and 20 native prototypes and tested them with users by conducting more than 70
                            face-to-face interviews and by collecting over 100 responses to our UX surveys. We took
                            extra care to conduct user testing with people from diverse backgrounds to prevent our
                            learnings from being biased.</p>
                    </div>
                    <div class="section-segment">
                        <h3>Discovery</h3>
                        <p>To design relevant and engaging experiences and interactions, I had to identify the fraud
                            signals needed for Machine Learning models, as well as empathise with users’ expectations
                            and concerns regarding facial verification. I took a user-centred approach and designed 25
                            prototypes with various interactions. Then, with the help of the UX Researcher, we conducted
                            interviews with users.</p>
                    </div>
                    <div class="section-media">
                        <video class="media-container" controls>
                            <source src="assets/motion/Discovery.mp4" type="video/mp4">
                        </video>
                        <!--<button class="custom-play"><img src="assets/icons/play.svg" alt=""><span class="custom-play-label">Play video</span></button>-->
                        <p class="media-caption">Example of a few design prototypes</p>
                    </div>
                    <div class="section-segment">
                        <p>From these interviews we learned the following:</p>
                        <ul class="content-list">
                            <li>Users prefer captures with minimal and/or simple interactions.</li>
                            <li>The speed of the capture process should be well balanced: if it is too slow users are
                                frustrated, and the product feels laggy. If it is too fast users can get confused, feel
                                a lack of control, or perceive the product as less reliable.</li>
                            <li>It is important for users to understand the relationship between a required interaction
                                and a facial verification process (e.g. capturing more details of the face) and the
                                value they get from that interaction (e.g. security purposes).</li>
                            <li>Using patterns from gaming can help people understand and engage with the required
                                interactions. However, the verification process shouldn’t feel like a game; it should be
                                serious and professional.</li>
                            <li>Users believe that the user interface reflects the product’s reliability and its
                                technological efficiency.</li>
                        </ul>
                    </div>
                </div>
                <div class="section-content">
                    <div class="section-segment">
                        <h3>Device movement VS Head movement</h3>
                        <p>After the interviews, I asked Applied Scientists to review the data that was generated by the
                            different prototypes. We discovered that the prototypes that captured users’ faces in motion
                            provided significantly better signals for our Machine Learning models to detect fraud.</p>
                        <p>To define the ideal movement that would generate good signals (a device movement or a head
                            movement), I created 4 design prototypes and tested users’ reactions to lateral and circular
                            movements with their devices filming their faces (see below).</p>
                    </div>
                    <div class="section-media">
                        <video class="media-container" controls>
                            <source src="assets/motion/Movement-design.mp4" type="video/mp4">
                        </video>
                        <p class="media-caption">The 4 design prototypes</p>
                    </div>
                    <div class="section-segment">
                        <p>We were able to identify the kind of movements with which people felt the most comfortable.
                            But since the design prototypes were not responsive to live movements, the users’ feedback
                            was insufficient. Subsequently, I worked with an iOS engineer and created 20 native
                            prototypes that we tested with users (see below).</p>
                    </div>
                    <div class="section-media">
                        <video class="media-container" controls>
                            <source src="assets/motion/Movement-native.mp4" type="video/mp4">
                        </video>
                        <p class="media-caption">Example of a few native prototypes</p>
                    </div>
                    <div class="section-segment">
                        <p>According to our tests, head motions felt more natural. Users intuitively understood the
                            connection between the movement and the verification process. Head motions were also more
                            predictable as the possible physical movements are limited. Overall, users preferred a
                            lateral head-turn movement which provided enough signals for Machine Learning models. We
                            discovered that requiring users to turn their heads in a specific order was limiting users’
                            control, and they preferred the freedom of turning their heads as they wished. Additionally,
                            a majority of users wanted to be able to keep an eye on their screen while turning their
                            heads, meaning we had to reduce the range of movement required.</p>
                        <p>Eventually, I created a completion pattern as an intuitive way of guiding our users. As the
                            users turn their heads to the left or right, a progress line follows their head movement and
                            indicates when a side is complete. I also added vibrations at key moments to draw users’
                            attention.</p>
                    </div>
                    <div class="section-media">
                        <video class="media-container" controls>
                            <source src="assets/motion/Completion-pattern-head-haptics.mp4" type="video/mp4">
                        </video>
                        <p class="media-caption">Completion pattern with vibrations (audio ON)</p>
                    </div>
                    <div class="section-segment">
                        <h3>Validation on all platforms</h3>
                        <p>After finding the best user experience for iOS users, I needed to check if our findings also
                            apply to Android and Web (desktop) users. I worked with engineers from the three platforms
                            to create and test native prototypes on iOS, Android, and Web (see below).</p>
                    </div>
                    <div class="section-media">
                        <video class="media-container" controls>
                            <source src="assets/motion/Platforms.mp4" type="video/mp4">
                        </video>
                        <p class="media-caption">The head-turn experience on all platforms</p>
                    </div>
                    <div class="section-segment">
                        <p>Even though users from the different platforms tend to have their own mental models (for
                            instance, iOS users are used to Face ID head-roll motion), all users were able to use our
                            new head-turn experience with no problem.</p>
                        <p>There were a few adjustments that needed to be made to provide the same experience on all
                            three platforms. Our team had to refine the pattern on Android and Web as their face
                            tracking was not as smooth as iOS. We also realised how much the difference between devices
                            and cameras could impact the user experience. This pushed us to test more devices.</p>
                    </div>
                    <div class="section-segment">
                        <h3>Alpha release</h3>
                        <p>Based on all the previous learnings, I designed a simple flow with the lateral head-turn
                            experience that would fit into our overall identity verification process. I then worked with
                            iOS and Android engineers to implement Motion in our Software Development Kit (SDK). (see
                            below).</p>
                        <p>Before launching this product with real customers, we asked 40 users to test it and to fill
                            out a UX survey to understand how people were experiencing Motion at a bigger scale. This UX
                            survey will be re-used for future major updates. This way we can compare results and measure
                            improvements over time. Finally, our Product Manager recruited 3 customers to Alpha test the
                            new Motion product.</p>
                    </div>
                    <div class="section-media">
                        <video class="media-container" controls>
                            <source src="assets/motion/Final.mp4" type="video/mp4">
                        </video>
                        <p class="media-caption">The entire Alpha Motion flow</p>
                    </div>
                </div>
            </div>
            <div class="article-quote">
                <img src="assets/icons/quote.svg" alt="">
                <h3><span class="quote-highlight">Motion enables our customers to set up an account in seconds</span>
                    and be on their way on one of our mopeds, while enabling us to <span class="quote-highlight">keep
                        operating costs low and run efficiently</span> as an agile and high-growth business.</h3>
                <div class="author-wrapper">
                    <p class="name">Rick van’t Hof</p>
                    <p class="company">Product @Check</p>
                </div>
            </div>
            <div class="article-section">
                <h2>Results</h2>
                <div class="section-content">
                    <div class="section-segment">
                        <h3>Measuring success</h3>
                        <p>We were all extremely proud to see real people using Motion to verify their identity with no
                            problem! We are now waiting for more users to capture their faces via Motion so that we can
                            learn from them and move to the next stage of iterations.</p>
                        <p>The qualitative and quantitative feedback we got from users, and metrics we tracked from our
                            production data, allowed us to analyse how well we performed against our goals so far.
                            Quality of the user experience measured against the product principles that we created:</p>
                        <div class="section-table">
                            <div class="table-item">
                                <h4>Simplicity</h4>
                                <p>82.5% of users found the steps easy to complete and 90% of users succeeded in
                                    capturing their faces on their first try.</p>
                            </div>
                            <div class="table-item">
                                <h4>Control</h4>
                                <p>Users can decide the order of head-turns and keep their eyes on their screen.</p>
                            </div>
                            <div class="table-item">
                                <h4>Speed</h4>
                                <p>The head turn interaction is fast, taking only 5 seconds (median) for people to
                                    complete.</p>
                            </div>
                            <div class="table-item">
                                <h4>Delightfulness</h4>
                                <p>92.5% of users reported a positive experience.</p>
                            </div>
                            <div class="table-item">
                                <h4>Accessibility</h4>
                                <p>An accessibility audit has been performed by the <a href="" target="_blank">Digital
                                        Accessibility Centre</a> (DAC). Motion Alpha is already very accessible. It only
                                    needs more work on supporting screen readers to be <a href="" target="_blank">level
                                        AA</a> (accessibility standard in digital services).</p>
                            </div>
                            <div class="table-item">
                                <h4>Transparency</h4>
                                <p>Users can see which data will be collected. To be fully transparent, 45% of users
                                    said they would like to see a preview of the recording.</p>
                            </div>
                        </div>
                        <p>Technical performances of our product measured against key performance indicators:</p>
                        <div class="section-table">
                            <div class="table-item">
                                <h4>Automation</h4>
                                <p>We successfully achieved a product with 100% automation.</p>
                            </div>
                            <div class="table-item">
                                <h4>Processing time</h4>
                                <p>99% of users’ faces are processed in less than 20 seconds.</p>
                            </div>
                            <div class="table-item">
                                <h4>Pass rate</h4>
                                <p>96.6% of users’ faces have been cleared.</p>
                            </div>
                            <div class="table-item">
                                <h4>False Acceptance Rate (FAR)</h4>
                                <p>We are below 1% of falsely cleared users.</p>
                            </div>
                            <div class="table-item">
                                <h4>False rejection Rate (FRR)</h4>
                                <p>We are below 1% of falsely rejected users.</p>
                            </div>
                            <div class="table-item">
                                <h4>Fraud prevention</h4>
                                <p>We were granted <a href="" target="_blank">iBeta level 2</a> on both iOS and Android.
                                </p>
                            </div>
                        </div>
                    </div>
                    <div class="section-segment">
                        <h3>Next steps</h3>
                        <p>Now after we have released the new Motion product for Alpha customers, I will work with a
                            Product Operations Analyst to track specific UX metrics and measure the performance of
                            Motion at scale (e.g. drop-off, completion timing, percentages of first-time success, etc.).
                            I will then turn metrics from production data into insights to fine-tune the user
                            experience. I will also work on accessibility (e.g. support screen readers for visually
                            impaired users) and on increasing the device and platform coverage.</p>
                        <p>Since this article was written, we have launched our Beta release in September 2022. The next
                            step is a General Availability release when the product will be available for every
                            customer.</p>
                    </div>
                    <div class="section-media">
                        <div class="carousel-container">
                            <div class="carousel">
                                <div class="carousel-slide">
                                    <div class="img-container">
                                        <img
                                            src="">
                                    </div>
                                    <p class="media-caption">Image 1.</p>
                                </div>
                                <div class="carousel-slide">
                                    <div class="img-container">
                                        <img
                                            src="">
                                    </div>
                                    <p class="media-caption">Image 2.</p>
                                </div>
                                <div class="carousel-slide">
                                    <div class="img-container">
                                        <img
                                            src="">
                                    </div>
                                    <p class="media-caption">Image 3.</p>
                                </div>
                            </div>
                            <div class="carousel-controls">
                                <button id="prev"><img src="assets/icons/carousel-left.svg" alt=""></button>
                                <div class="indicators"></div>
                                <button id="next"><img src="assets/icons/carousel-right.svg" alt=""></button>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            <div class="article-metrics">
                <div class="metric-item">
                    <h2 class="metric-number gradient-text">461</h2>
                    <p class="metric-caption">Customers</p>
                </div>
                <div class="metric-item">
                    <h2 class="metric-number gradient-text">5M</h2>
                    <p class="metric-caption">Monthly scans</p>
                </div>
                <div class="metric-item">
                    <h2 class="metric-number gradient-text">97%</h2>
                    <p class="metric-caption">Success rate</p>
                </div>
            </div>
            <div class="article-section">
                <h2>Learnings</h2>
                <div class="section-content">
                    <div class="section-segment">
                        <h3>Cross-functional collaboration</h3>
                        <p>Building Motion was a team effort. I constantly collaborated with different stakeholders from
                            various functions, listening to my colleagues and making sure that I have a good
                            understanding of what they were trying to achieve while advocating for good design. This was
                            essential to designing a realistic solution.</p>
                    </div>
                    <div class="section-segment">
                        <h3>Iterative process</h3>
                        <p>My team followed a two-week sprint approach. This allowed me to focus on designing and
                            building essentials, test various prototypes, and gather feedback from real users as quickly
                            as possible. Consequently, I was able to learn, reflect, and iterate fast. This approach has
                            given my team and me confidence in the success of my designs throughout the entire process.
                        </p>
                    </div>
                    <div class="section-segment">
                        <h3>Measuring success</h3>
                        <p>To reflect and improve on my solutions, measuring success was done at each iteration. The way
                            in which I measured success evolved according to the stage of the product. In the early
                            stages, we mainly collected qualitative data by talking directly to users. Then, we
                            collected both qualitative and quantitative data by testing a few prototypes on a bigger
                            scale. Finally, we collected quantitative data by tracking users’ behaviour in production.
                            My job was to translate these different types of data into insights to validate the success
                            of my designs.</p>
                        <p>Oh, and my face eventually appeared on a billboard in Las Vegas as part of our launch of
                            Motion ads during the Money20/20 event.</p>
                    </div>
                    <div class="section-media">
                        <video class="media-container" controls>
                            <source src="assets/motion/Billboard.mp4" type="video/mp4">
                        </video>
                        <p class="media-caption">The appearance that made me famous</p>
                    </div>
                </div>

            </div>
            <div class="article-press">
                <h3>Press</h3>
                <div class="press-link-wrapper">
                    <div class="link-item">
                        <img src="assets/icons/link.svg" alt="">
                        <div class="link-item-wrapper">
                            <a href="https://thenextweb.com/news/onfido-launches-industry-first-biometric-id-verification-system-motion"
                                class="title" target="_blank">UK scaleup launches groundbreaking approach to ID
                                verification</a>
                            <p class="content">The Next Web</p>
                        </div>
                    </div>
                    <div class="link-item">
                        <img src="assets/icons/link.svg" alt="">
                        <div class="link-item-wrapper">
                            <a href="assets/press-backup/onfido-motion-bbc.mp4" class="title" target="_blank">Featured
                                in “The Secret Genius of Modern Life”</a>
                            <p class="content">BBC</p>
                        </div>
                    </div>
                    <div class="link-item">
                        <img src="assets/icons/link.svg" alt="">
                        <div class="link-item-wrapper">
                            <a href="https://onfido.com/press-release/onfido-launches-motion-the-next-generation-of-facial-biometric-technology/"
                                class="title" target="_blank">Onfido launches Motion, the next generation of facial
                                biometric technology</a>
                            <p class="content">Onfido Blog post</p>
                        </div>
                    </div>
                    <div class="link-item">
                        <img src="assets/icons/link.svg" alt="">
                        <div class="link-item-wrapper">
                            <a href="https://go.onfido.com/landing/building-ai-without-bias" class="title"
                                target="_blank">Building AI without bias. Reducing bias in biometrics</a>
                            <p class="content">Onfido Whitepaper</p>
                        </div>
                    </div>
                </div>
            </div>
            <div class="article-other-projects">
                <button class="button-project previous">
                    <img src="assets/icons/arrow-left-big.svg" alt="">
                    <div class="button-wrapper">
                        <p class="button-title">Previous project</p>
                        <p class="button-content">ID Verification</p>
                    </div>
                </button>
                <button class="button-project next">
                    <div class="button-wrapper">
                        <p class="button-title">Next project</p>
                        <p class="button-content">NFC Scan</p>
                    </div>
                    <img src="assets/icons/arrow-right-big.svg" alt="">
                </button>
            </div>
    </main>
    <footer>
        <div id="footer-container">
            <h1>Let's connect</h1>
            <div id="connect-description">
                <p>Feel free to reach out for collaborations</p>
                <a href="mailto:theoricharddesign@gmail.com">theoricharddesign@gmail.com</a>
            </div>
            <div id="social">
                <ul>
                    <li><a href="https://www.linkedin.com/in/th%C3%A9o-richard-501036101/" target="_blank"><img
                                src="assets/icons/social-linkedin.svg" alt="linkedin"></a></li>
                    <li><a href="https://medium.com/@theo-richard" target="_blank"><img
                                src="assets/icons/social-medium.svg" alt="medium"></a></li>
                    <li><a href="https://x.com/theorichardd?s=21" target="_blank"><img
                                src="assets/icons/social-twitter.svg" alt="twitter"></a></li>
                </ul>
            </div>
            <a href="#" id="anchor-up">
                <svg width="16" height="16" viewBox="0 0 16 16" fill="currentColor" xmlns="http://www.w3.org/2000/svg">
                    <path fill-rule="evenodd" clip-rule="evenodd"
                        d="M7.00001 4.41422L3.70711 7.70712C3.31658 8.09764 2.68342 8.09764 2.29289 7.70712C1.90237 7.31659 1.90237 6.68343 2.29289 6.2929L7.29289 1.2929C7.68342 0.902379 8.31658 0.90238 8.70711 1.2929L13.7071 6.2929C14.0976 6.68343 14.0976 7.31659 13.7071 7.70712C13.3166 8.09764 12.6834 8.09764 12.2929 7.70712L9.00001 4.41423L8.99999 14C8.99999 14.5523 8.55228 15 7.99999 15C7.44771 15 6.99999 14.5523 6.99999 14L7.00001 4.41422Z"
                        fill="currentColor" />
                </svg>
            </a>
            <div id="copyright">
                <img src="assets/icons/copyright-inside.svg" alt="">
                <img src="assets/icons/copyright-outside.svg" alt="" id="copyright-rotate">
            </div>
        </div>
    </footer>
    <script src="js/main.js"></script>
</body>

</html>